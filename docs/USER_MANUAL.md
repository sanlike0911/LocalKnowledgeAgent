# LocalKnowledgeAgent ユーザーマニュアル

バージョン: 1.0.0  
最終更新: 2025-01-01

## 目次

1. [はじめに](#はじめに)
2. [画面構成](#画面構成)
3. [基本操作](#基本操作)
4. [高度な使い方](#高度な使い方)
5. [FAQ・トラブルシューティング](#faqトラブルシューティング)

## はじめに

LocalKnowledgeAgentは、あなたの文書を智能的に管理し、AI による質問応答システムを提供します。  
完全にローカル環境で動作し、プライバシーを保護しながら高精度な情報検索が可能です。

### 主要機能

- 📄 **多形式文書対応**: PDF, TXT, DOCX, Markdown
- 🔍 **高精度検索**: ベクトル検索による意味理解
- 🤖 **AI回答生成**: 複数LLMモデル対応
- 🎌 **日本語最適化**: 常に日本語で回答
- 📊 **進捗可視化**: 処理状況をリアルタイム表示

## 画面構成

### メイン画面 (SCR-01)

チャット形式でAIと対話する画面です。

```
┌─────────────────────────────────────┐
│  📚 LocalKnowledgeAgent            │
├─────────────────────────────────────┤
│  💬 チャット履歴                    │
│  ┌─────────────────────────────────┐ │
│  │ ユーザー: 質問内容              │ │
│  │ AI: 回答内容                    │ │
│  │   📄 参考ソース: filename.pdf   │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │ 質問を入力... [送信]            │ │
│  └─────────────────────────────────┘ │
└─────────────────────────────────────┘
```

### 設定画面 (SCR-02)

システム設定とインデックス管理を行う画面です。

```
┌─────────────────────────────────────┐
│  ⚙️ 設定                           │
├─────────────────────────────────────┤
│  🤖 LLMモデル設定                   │
│  📁 フォルダ管理                    │
│  🔍 インデックス管理                 │
│  💾 設定保存                        │
└─────────────────────────────────────┘
```

## 基本操作

### 1. 初回セットアップ

#### Step 1: 設定画面に移動

1. サイドバーの「⚙️ 設定」をクリック

#### Step 2: LLMモデル選択

1. **LLMモデル設定**セクション
2. ドロップダウンから使用するモデルを選択
3. モデル情報（サイズ、更新日時）を確認

**推奨モデル**:
- `llama3:8b`: バランスの取れた高性能モデル
- `gemma2:2b`: 軽量・高速モデル
- `mistral:latest`: 多言語対応モデル

#### Step 3: フォルダ設定

1. **フォルダ管理**セクション
2. 知識ベースにしたいフォルダパスを入力
3. 「フォルダ追加」ボタンをクリック

**例**:
```
C:\Documents\仕事資料
C:\Users\username\MyDocuments\研究資料
/home/user/documents/manual
```

#### Step 4: インデックス作成

1. **インデックス管理**セクション
2. 「インデックス作成」ボタンをクリック
3. 進捗バーで処理状況を確認
4. 完了まで待機 (数分〜数十分)

#### Step 5: 設定保存

1. **設定保存**セクション
2. 「設定保存」ボタンをクリック
3. 設定が正常に保存されることを確認

### 2. 質問・回答の基本操作

#### 質問の入力

1. **メイン画面**に移動
2. チャット入力欄に質問を入力
3. Enterキーまたは「送信」ボタンで送信

**質問例**:
```
「代表取締役の出張費規定について教えて」
「安全管理に関する規則は？」  
「契約書のテンプレートはありますか？」
```

#### 回答の確認

AI回答には以下の情報が含まれます:

1. **回答内容**: AIが生成した回答文
2. **参考ソース**: 回答の根拠となった文書
3. **類似度**: 関連度の数値 (0-100%)
4. **ファイル名**: 参考文書のファイル名

#### 履歴管理

- チャット履歴は自動保存されます
- 最大50件まで保持されます
- ブラウザをリフレッシュしても履歴は保持されます

### 3. 文書管理

#### 対応ファイル形式

| 形式 | 拡張子 | 特徴 |
|------|--------|------|
| PDF | `.pdf` | レイアウト保持 |
| テキスト | `.txt` | 軽量・高速処理 |
| Word文書 | `.docx` | 豊富な書式 |
| Markdown | `.md` | 構造化テキスト |

#### ファイルサイズ制限

- **最大ファイルサイズ**: 50MB
- **推奨サイズ**: 10MB以下 (処理速度重視)
- **大容量ファイル**: 分割推奨

#### フォルダ構造例

```
知識ベースフォルダ/
├── 規程集/
│   ├── 就業規則.pdf
│   ├── 安全管理規程.docx
│   └── 出張旅費規程.txt
├── マニュアル/
│   ├── 操作手順書.md
│   └── FAQ集.pdf
└── 契約書/
    ├── 雇用契約書テンプレート.docx
    └── 業務委託契約書.pdf
```

## 高度な使い方

### 1. 効果的な質問テクニック

#### 具体的な質問

❌ **悪い例**: 「規程について」  
✅ **良い例**: 「有給休暇の取得手続きについて詳しく教えて」

#### 複数の観点からの質問

✅ **例**: 「新入社員の研修制度について、期間、内容、費用の観点で教えて」

#### 条件指定の質問

✅ **例**: 「売上高5000万円以下の中小企業向けの税制優遇措置は？」

### 2. インデックス管理

#### インデックスの更新

新しい文書を追加した場合:

1. 設定画面の「インデックス管理」
2. 「インデックス削除」→「インデックス作成」で更新
3. または「インデックス作成」で追加分を処理

#### インデックスステータス

- 🟢 **作成済み**: 正常に利用可能
- 🟡 **作成中**: 処理中 (待機してください)
- 🔴 **未作成**: インデックス作成が必要
- ❌ **エラー**: 再作成が必要

#### 処理時間目安

| 文書数 | 処理時間 |
|--------|----------|
| 10-50個 | 1-3分 |
| 50-100個 | 3-8分 |
| 100-500個 | 8-20分 |
| 500個以上 | 20分以上 |

### 3. モデル選択の指針

#### 用途別推奨モデル

**日常業務・一般質問**:
- `llama3:8b`: バランス型、推奨
- `gemma2:9b`: 高精度、やや重い

**軽量・高速処理**:
- `gemma2:2b`: 最軽量、基本的な質問に対応

**専門分野・複雑な質問**:
- `mistral:latest`: 多言語・専門性
- `llama3:70b`: 最高品質 (大容量メモリ必要)

#### パフォーマンス比較

| モデル | 速度 | 精度 | メモリ使用量 |
|--------|------|------|--------------|
| gemma2:2b | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | 2GB |
| llama3:8b | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 6GB |
| mistral | ⭐⭐⭐ | ⭐⭐⭐⭐ | 5GB |
| llama3:70b | ⭐⭐ | ⭐⭐⭐⭐⭐ | 48GB |

### 4. カスタマイズ設定

#### 設定ファイル編集

高度な設定は `data/config.json` で変更可能:

```json
{
  "ollama_model": "llama3:8b",
  "max_chat_history": 50,
  "max_file_size_mb": 50,
  "force_japanese_response": true
}
```

#### 主要設定項目

- `max_chat_history`: チャット履歴保持数
- `max_file_size_mb`: 最大ファイルサイズ
- `force_japanese_response`: 日本語強制回答

## FAQ・トラブルシューティング

### よくある質問

#### Q1: 文書が検索されない

**A**: 以下を確認してください:
1. インデックスが作成済みか確認
2. 対応ファイル形式か確認 (PDF, TXT, DOCX, MD)
3. ファイルサイズが50MB以下か確認
4. フォルダパスが正しいか確認

#### Q2: 回答が英語で表示される

**A**: 設定で日本語強制回答が有効になっているか確認:
1. 設定画面で「設定保存」を実行
2. `data/config.json`で`"force_japanese_response": true`を確認

#### Q3: 処理が遅い

**A**: 以下の最適化を試してください:
1. より軽量なモデル (`gemma2:2b`) を使用
2. インデックス対象ファイル数を削減
3. 不要な他のアプリケーションを終了

#### Q4: モデルが選択できない

**A**: Ollamaモデルの確認:
```bash
ollama list
ollama pull llama3:8b
```

### エラー対処法

#### CFG-007: 設定項目不足エラー

**対処法**:
1. 設定画面ですべての必須項目を入力
2. 「設定保存」ボタンをクリック
3. アプリケーションを再起動

#### QA-001: 関連文書が見つからない

**対処法**:
1. インデックス作成が完了しているか確認
2. 質問内容を具体的に変更
3. 文書内に該当する情報があるか確認

#### IDX-011: インデックス削除エラー

**対処法**:
1. アプリケーションを一度終了
2. `data/chroma_db` フォルダを削除
3. アプリケーションを再起動して再作成

### パフォーマンスチューニング

#### システムリソース最適化

**メモリ使用量削減**:
- 軽量モデル使用: `gemma2:2b`
- 同時処理制限: 他アプリ終了
- インデックス対象ファイル削減

**処理速度向上**:
- SSDを使用 (HDD比で3-5倍高速化)
- CPUクロック数を向上
- 不要なバックグラウンドプロセス終了

#### 大量文書の処理

**1000個以上の文書を扱う場合**:
1. フォルダを分割してインデックス作成
2. カテゴリ別に複数のインデックスを作成
3. 処理時間を考慮して夜間実行

### サポート・コミュニティ

#### ヘルプリソース

- **GitHub Issues**: バグレポート・機能要求
- **Wiki**: 詳細技術情報
- **Discussions**: ユーザーコミュニティ

#### ログ情報の取得

問題発生時は以下の情報をお知らせください:

```bash
# ログファイル確認
cat logs/app.log

# システム情報
python --version
ollama --version
```

---

**さらに詳しい情報は[技術文書](design-specification.md)をご覧ください。**