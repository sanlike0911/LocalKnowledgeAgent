"""
ãƒ¡ã‚¤ãƒ³ç”»é¢UIå®Ÿè£… (TDD Green ãƒ•ã‚§ãƒ¼ã‚º)
ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãƒ»é€²æ—è¡¨ç¤ºãƒ»QAã‚·ã‚¹ãƒ†ãƒ çµ±åˆæ©Ÿèƒ½ã‚’æä¾›
"""

import streamlit as st
import logging
import time
from typing import Dict, Any, List, Optional, Iterator
from datetime import datetime
from contextlib import contextmanager

from src.models.chat_history import ChatHistory
from src.utils.session_state import ChatMessage
from src.models.config import Config
from src.logic.qa import RAGPipeline
from src.logic.indexing import ChromaDBIndexer
from src.logic.config_manager import ConfigManager
from src.exceptions.base_exceptions import QAError, IndexingError, ConfigError
from src.utils.structured_logger import get_logger
from src.security.xss_protection import sanitize_user_input
from src.utils.progress_utils import ProgressTracker, should_show_progress
from src.utils.cancellation_utils import CancellableOperation


class StreamlitChatManager:
    """
    Streamlit ãƒãƒ£ãƒƒãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹
    
    ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤ºãƒ»æ›´æ–°ãƒ»ç®¡ç†æ©Ÿèƒ½ã‚’æä¾›
    """
    
    def __init__(self, indexer=None):
        """Streamlit ãƒãƒ£ãƒƒãƒˆç®¡ç†ã‚’åˆæœŸåŒ–"""
        self.logger = get_logger(__name__)
        self.indexer = indexer
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
        
        if 'processing' not in st.session_state:
            st.session_state.processing = False
        
        if 'cancel_requested' not in st.session_state:
            st.session_state.cancel_requested = False
    
    def display_chat_history(self) -> None:
        """
        ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
        """
        try:
            chat_history = st.session_state.get('chat_history', [])
            
            if not chat_history:
                return
            
            for message in chat_history:
                role = message.get('role', 'user')
                content = message.get('content', '')
                sources = message.get('sources', [])
                
                with st.chat_message(role):
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’è¡¨ç¤º
                    st.write(content)
                    
                    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã€ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚‚è¡¨ç¤º
                    if role == 'assistant' and sources:
                        self._display_sources(sources)
                        
        except Exception as e:
            self.logger.error(f"ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
            st.error("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
    
    def _display_sources(self, sources: List[Dict[str, Any]]) -> None:
        """
        ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¡¨ç¤º
        
        Args:
            sources: ã‚½ãƒ¼ã‚¹æƒ…å ±ãƒªã‚¹ãƒˆ
        """
        if not sources:
            return
        
        with st.expander(f"ğŸ“š å‚è€ƒã‚½ãƒ¼ã‚¹ ({len(sources)}ä»¶)", expanded=False):
            for i, source in enumerate(sources, 1):
                # ChromaDBã‹ã‚‰å–å¾—ã—ãŸmetadataã‚’ç¢ºèª
                metadata = source.get('metadata', {})
                filename = metadata.get('document_filename') or source.get('filename', 'ä¸æ˜ãªãƒ•ã‚¡ã‚¤ãƒ«')
                distance = source.get('distance', 0.0)
                preview = source.get('content_preview', '')
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åè¡¨ç¤ºã®æ”¹å–„
                if filename == 'ä¸æ˜ãªãƒ•ã‚¡ã‚¤ãƒ«' or filename == 'ä¸æ˜':
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä»–ã®æƒ…å ±ã‚’è©¦ã™
                    chunk_index = metadata.get('chunk_index', 0)
                    filename = f"æ–‡æ›¸ {i} (ãƒãƒ£ãƒ³ã‚¯{chunk_index})"
                
                st.markdown(f"**{i}. {filename}**")
                
                # è·é›¢å€¤ã‹ã‚‰é¡ä¼¼åº¦ã¸ã®å¤‰æ›ã‚’æ”¹å–„
                similarity_score = self._calculate_similarity_score(distance)
                st.markdown(f"é¡ä¼¼åº¦: {similarity_score}")
                
                if preview:
                    st.markdown(f"å†…å®¹: {preview}")
                
                if i < len(sources):
                    st.markdown("---")
    
    def _calculate_similarity_score(self, distance: float) -> str:
        """
        è·é›¢å€¤ã‹ã‚‰é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        
        Args:
            distance: ChromaDBã‹ã‚‰è¿”ã•ã‚Œã‚‹è·é›¢å€¤
            
        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸé¡ä¼¼åº¦è¡¨ç¤º
        """
        try:
            # è·é›¢å€¤ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
            if distance < 0:
                return "è¨ˆç®—ä¸å¯ (è² ã®è·é›¢å€¤)"
            elif distance > 100:
                # ç•°å¸¸ã«å¤§ããªè·é›¢å€¤ã®å ´åˆã€æ­£è¦åŒ–ã‚’è©¦ã¿ã‚‹
                # ChromaDBã®ã‚³ã‚µã‚¤ãƒ³è·é›¢ã¯é€šå¸¸0-2ã®ç¯„å›²ã ãŒã€
                # ç•°å¸¸å€¤ã®å ´åˆã¯åˆ¥ã®è¨ˆç®—æ–¹å¼ã‚’ä½¿ç”¨
                if distance > 1000:
                    return "ä½ (è·é›¢å€¤ç•°å¸¸)"
                else:
                    # æ­£è¦åŒ–ã‚’è©¦ã™
                    normalized_distance = min(distance / 100.0, 2.0)
                    similarity_percent = max(0, (2.0 - normalized_distance) / 2.0 * 100)
                    return f"{similarity_percent:.1f}% (æ­£è¦åŒ–æ¸ˆã¿)"
            elif distance <= 2.0:
                # æ­£å¸¸ãªç¯„å›²ã®è·é›¢å€¤ï¼ˆã‚³ã‚µã‚¤ãƒ³è·é›¢ï¼š0-2ï¼‰
                similarity_percent = max(0, (2.0 - distance) / 2.0 * 100)
                return f"{similarity_percent:.1f}%"
            else:
                # 2ã‚’è¶…ãˆã‚‹å ´åˆ
                return f"ä½ (è·é›¢å€¤: {distance:.2f})"
                
        except Exception as e:
            return f"è¨ˆç®—ã‚¨ãƒ©ãƒ¼ ({str(e)})"
    
    def add_user_message(self, message: str) -> None:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        
        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        try:
            chat_entry = {
                'role': 'user',
                'content': message,
                'timestamp': datetime.now().isoformat()
            }
            
            st.session_state.chat_history.append(chat_entry)
            
            self.logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ", extra={
                "message_length": len(message),
                "history_count": len(st.session_state.chat_history)
            })
            
        except Exception as e:
            self.logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
    
    def add_assistant_message(
        self,
        message: str,
        sources: Optional[List[Dict[str, Any]]] = None,
        processing_time: Optional[float] = None
    ) -> None:
        """
        ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        
        Args:
            message: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            sources: ã‚½ãƒ¼ã‚¹æƒ…å ±ãƒªã‚¹ãƒˆ
            processing_time: å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰
        """
        try:
            chat_entry = {
                'role': 'assistant',
                'content': message,
                'timestamp': datetime.now().isoformat()
            }
            
            if sources:
                chat_entry['sources'] = sources
            
            if processing_time:
                chat_entry['processing_time'] = processing_time
            
            st.session_state.chat_history.append(chat_entry)
            
            self.logger.info("ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ", extra={
                "message_length": len(message),
                "sources_count": len(sources) if sources else 0,
                "processing_time": processing_time
            })
            
        except Exception as e:
            self.logger.error(f"ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
    
    def clear_chat_history(self) -> None:
        """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"""
        try:
            history_count = len(st.session_state.get('chat_history', []))
            st.session_state.chat_history = []
            
            self.logger.info(f"ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢å®Œäº†: {history_count}ä»¶å‰Šé™¤")
            
        except Exception as e:
            self.logger.error(f"ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_conversation_history_for_qa(self) -> List[Dict[str, str]]:
        """
        QAã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
        
        Returns:
            List[Dict[str, str]]: QAç”¨ä¼šè©±å±¥æ­´
        """
        try:
            chat_history = st.session_state.get('chat_history', [])
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å›ç­”ã¾ã§å«ã‚€å±¥æ­´ã®ã¿ã‚’æŠ½å‡º
            qa_history = []
            for message in chat_history:
                if message['role'] in ['user', 'assistant']:
                    qa_history.append({
                        'role': message['role'],
                        'content': message['content']
                    })
            
            # æœ€å¾ŒãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã¯é™¤å¤–ï¼ˆç¾åœ¨å‡¦ç†ä¸­ã®ãŸã‚ï¼‰
            if qa_history and qa_history[-1]['role'] == 'user':
                qa_history = qa_history[:-1]
            
            return qa_history[-10:]  # ç›´è¿‘10ä»¶ã®ã¿
            
        except Exception as e:
            self.logger.error(f"ä¼šè©±å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def handle_chat_input(self, placeholder: str = "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...") -> Optional[str]:
        """
        ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚’å‡¦ç†
        
        Args:
            placeholder: å…¥åŠ›æ¬„ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            
        Returns:
            Optional[str]: å…¥åŠ›ã•ã‚ŒãŸè³ªå•ï¼ˆãªã‘ã‚Œã°Noneï¼‰
        """
        try:
            # å‡¦ç†ä¸­ã¯å…¥åŠ›ã‚’ç„¡åŠ¹åŒ–
            disabled = st.session_state.get('processing', False)
            
            user_input = st.chat_input(
                placeholder=placeholder,
                disabled=disabled
            )
            
            # ç©ºã®å…¥åŠ›ã‚„ç©ºç™½ã®ã¿ã®å…¥åŠ›ã‚’é™¤å¤–
            if user_input and user_input.strip():
                return user_input.strip()
            
            return None
            
        except Exception as e:
            self.logger.error(f"ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return None


class MainView(CancellableOperation):
    """
    ãƒ¡ã‚¤ãƒ³ç”»é¢UI ã‚¯ãƒ©ã‚¹
    
    Streamlit ãƒ¡ã‚¤ãƒ³ç”»é¢ã®è¡¨ç¤ºãƒ»æ“ä½œãƒ»QAã‚·ã‚¹ãƒ†ãƒ çµ±åˆã‚’ç®¡ç†
    """
    
    def __init__(self, indexer=None):
        """ãƒ¡ã‚¤ãƒ³ç”»é¢UIã‚’åˆæœŸåŒ–"""
        super().__init__("Main View")
        
        self.logger = get_logger(__name__)
        self.chat_manager = StreamlitChatManager()
        self.indexer = indexer
        
        # RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨Indexerã‚’åˆæœŸåŒ–
        self._initialize_qa_system()
        
        self.logger.info("ãƒ¡ã‚¤ãƒ³ç”»é¢UIåˆæœŸåŒ–å®Œäº†")
    
    def _initialize_qa_system(self) -> None:
        """QAã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–"""
        try:
            # è¨­å®šç®¡ç†
            config_manager = ConfigManager()
            config = config_manager.load_config()
            
            # ChromaDBã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ãŒæ¸¡ã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿åˆæœŸåŒ–
            if self.indexer is None:
                self.indexer = ChromaDBIndexer(
                    collection_name="knowledge_base", 
                    db_path=config.chroma_db_path,
                    embedding_model="nomic-embed-text"
                )
            
            # RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
            self.rag_pipeline = RAGPipeline(
                indexer=self.indexer,
                model_name=config.ollama_model
            )
            
            self.config = config
            
        except Exception as e:
            self.logger.error(f"QAã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.indexer = None
            self.rag_pipeline = None
            self.config = Config()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    
    def render(self) -> None:
        """ãƒ¡ã‚¤ãƒ³ç”»é¢ã‚’æç”»"""
        try:
            self._render_header()
            self._render_system_status()
            self._render_chat_interface()
            self._render_sidebar()
            
        except Exception as e:
            self.logger.error(f"ãƒ¡ã‚¤ãƒ³ç”»é¢æç”»ã‚¨ãƒ©ãƒ¼: {e}")
            st.error("ç”»é¢ã®æç”»ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
    
    def _render_header(self) -> None:
        """ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ã‚’æç”»"""
        st.title("ğŸ¤– LocalKnowledgeAgent")
        st.markdown("**ãƒ­ãƒ¼ã‚«ãƒ«çŸ¥è­˜ãƒ™ãƒ¼ã‚¹å¯¾å¿œAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ**")
        
        # ã‚·ã‚¹ãƒ†ãƒ å¥åº·çŠ¶æ…‹ã®ç°¡æ˜“è¡¨ç¤º
        if self.rag_pipeline:
            health_status = self.rag_pipeline.check_system_health()
            status_emoji = "ğŸŸ¢" if health_status['overall_status'] == 'healthy' else "ğŸŸ¡" if health_status['overall_status'] == 'degraded' else "ğŸ”´"
            st.markdown(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {status_emoji} {health_status['overall_status'].title()}")
        
        st.markdown("---")
    
    def _render_system_status(self) -> None:
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’æç”»"""
        if not self.rag_pipeline:
            st.warning("âš ï¸ QAã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆæƒ…å ±
        try:
            stats = self.indexer.get_collection_stats()
            doc_count = stats.get('document_count', 0)
            
            if doc_count == 0:
                st.info("ğŸ“š ã¾ã ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šç”»é¢ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.success(f"ğŸ“š {doc_count}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                
        except Exception as e:
            st.error(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    def _render_chat_interface(self) -> None:
        """ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æç”»"""
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
        self.chat_manager.display_chat_history()
        
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å‡¦ç†
        if user_input := self.chat_manager.handle_chat_input():
            self._process_user_input(user_input)
    
    def _process_user_input(self, user_input: str) -> None:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å‡¦ç†
        
        Args:
            user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
        """
        try:
            # XSSå¯¾ç­–ï¼šå…¥åŠ›ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚º
            sanitized_input = sanitize_user_input(user_input, allow_markdown=False)
            if sanitized_input != user_input:
                self.logger.warning("ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ã¾ã—ãŸ", extra={
                    "original_length": len(user_input),
                    "sanitized_length": len(sanitized_input)
                })
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆã¿ï¼‰
            self.chat_manager.add_user_message(sanitized_input)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å³åº§ã«è¡¨ç¤º
            with st.chat_message("user"):
                st.write(sanitized_input)
            
            # QAã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            if not self.rag_pipeline:
                with st.chat_message("assistant"):
                    st.error("QAã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
                return
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®å›ç­”ç”Ÿæˆï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆã¿å…¥åŠ›ã‚’ä½¿ç”¨ï¼‰
            if getattr(self.config, 'enable_streaming', True):
                self._process_streaming_question(sanitized_input)
            else:
                self._process_standard_question(sanitized_input)
                
        except Exception as e:
            self.logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            with st.chat_message("assistant"):
                st.error("è³ªå•ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
    
    def _process_standard_question(self, question: str) -> None:
        """
        æ¨™æº–çš„ãªè³ªå•å‡¦ç†
        
        Args:
            question: è³ªå•å†…å®¹
        """
        try:
            st.session_state.processing = True
            
            with st.chat_message("assistant"):
                with self.show_spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    
                    # ä¼šè©±å±¥æ­´ã‚’å–å¾—
                    conversation_history = self.chat_manager.get_conversation_history_for_qa()
                    
                    # QAå®Ÿè¡Œ
                    qa_result = self.rag_pipeline.answer_question(
                        question,
                        conversation_history=conversation_history,
                        top_k=getattr(self.config, 'max_search_results', 5)
                    )
                    
                    if qa_result:
                        # å›ç­”è¡¨ç¤º
                        st.write(qa_result['answer'])
                        
                        # ã‚½ãƒ¼ã‚¹æƒ…å ±è¡¨ç¤º
                        if qa_result.get('sources'):
                            self.chat_manager._display_sources(qa_result['sources'])
                        
                        # å‡¦ç†æ™‚é–“è¡¨ç¤º
                        processing_time = qa_result.get('processing_time', 0)
                        if processing_time > 0:
                            st.caption(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
                        
                        # å±¥æ­´ã«è¿½åŠ 
                        self.chat_manager.add_assistant_message(
                            qa_result['answer'],
                            qa_result.get('sources', []),
                            processing_time
                        )
                    else:
                        st.error("å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        
        except QAError as e:
            self.logger.error(f"QAã‚¨ãƒ©ãƒ¼: {e}")
            st.error(f"è³ªå•ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
        except Exception as e:
            self.logger.error(f"è³ªå•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            st.error("äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
            
        finally:
            st.session_state.processing = False
    
    def _process_streaming_question(self, question: str) -> None:
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è³ªå•å‡¦ç†
        
        Args:
            question: è³ªå•å†…å®¹
        """
        try:
            st.session_state.processing = True
            st.session_state.cancel_requested = False
            
            with st.chat_message("assistant"):
                # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
                answer_placeholder = st.empty()
                sources_placeholder = st.empty()
                status_placeholder = st.empty()
                
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³
                cancel_col1, cancel_col2 = st.columns([1, 4])
                with cancel_col1:
                    cancel_button = st.button("â¹ï¸ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", key=f"cancel_{time.time()}")
                
                if cancel_button:
                    st.session_state.cancel_requested = True
                
                # ä¼šè©±å±¥æ­´ã‚’å–å¾—
                conversation_history = self.chat_manager.get_conversation_history_for_qa()
                
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
                full_answer = ""
                sources = []
                processing_start = time.time()
                
                try:
                    stream = self.rag_pipeline.answer_question_stream(
                        question,
                        conversation_history=conversation_history,
                        top_k=getattr(self.config, 'max_search_results', 5)
                    )
                    
                    for chunk in stream:
                        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèª
                        if st.session_state.get('cancel_requested', False):
                            status_placeholder.warning("â¹ï¸ å‡¦ç†ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                            return
                        
                        chunk_type = chunk.get('type', 'unknown')
                        
                        if chunk_type == 'sources':
                            sources = chunk.get('sources', [])
                            
                        elif chunk_type == 'content':
                            content = chunk.get('content', '')
                            full_answer += content
                            
                            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
                            answer_placeholder.write(full_answer)
                            
                        elif chunk_type == 'complete':
                            full_answer = chunk.get('answer', full_answer)
                            break
                            
                        elif chunk_type == 'error':
                            error_msg = chunk.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')
                            status_placeholder.error(f"ã‚¨ãƒ©ãƒ¼: {error_msg}")
                            return
                    
                    # æœ€çµ‚çµæœè¡¨ç¤º
                    answer_placeholder.write(full_answer)
                    
                    if sources:
                        self.chat_manager._display_sources(sources)
                    
                    processing_time = time.time() - processing_start
                    status_placeholder.caption(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
                    
                    # å±¥æ­´ã«è¿½åŠ 
                    self.chat_manager.add_assistant_message(
                        full_answer,
                        sources,
                        processing_time
                    )
                    
                except Exception as e:
                    self.logger.error(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    status_placeholder.error("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                    
        except Exception as e:
            self.logger.error(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è³ªå•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            st.error("è³ªå•ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            
        finally:
            st.session_state.processing = False
            st.session_state.cancel_requested = False
    
    def _render_sidebar(self) -> None:
        """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’æç”»"""
        with st.sidebar:
            st.header("ğŸ› ï¸ æ“ä½œ")
            
            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢
            if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
                self.chat_manager.clear_chat_history()
                st.rerun()
            
            st.markdown("---")
            
            # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
            st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
            
            if self.rag_pipeline:
                health_status = self.rag_pipeline.check_system_health()
                
                st.json({
                    "ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹": health_status['overall_status'],
                    "ChromaDB": health_status['components'].get('chromadb', {}).get('status', 'unknown'),
                    "Ollama": health_status['components'].get('ollama', {}).get('status', 'unknown'),
                    "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°": health_status['components'].get('chromadb', {}).get('document_count', 0)
                })
            else:
                st.error("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“")
            
            st.markdown("---")
            
            # è¨­å®šæƒ…å ±
            st.header("âš™ï¸ ç¾åœ¨ã®è¨­å®š")
            
            config_summary = {
                "ãƒ¢ãƒ‡ãƒ«": getattr(self.config, 'ollama_model', 'llama3:8b'),
                "æœ€å¤§æ¤œç´¢çµæœæ•°": getattr(self.config, 'max_search_results', 5),
                "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°": "æœ‰åŠ¹" if getattr(self.config, 'enable_streaming', True) else "ç„¡åŠ¹",
                "è¨€èª": getattr(self.config, 'language', 'ja')
            }
            
            st.json(config_summary)
    
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ã‚½ãƒƒãƒ‰
    
    @contextmanager
    def show_spinner(self, message: str):
        """
        ã‚¹ãƒ”ãƒŠãƒ¼è¡¨ç¤ºã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        
        Args:
            message: ã‚¹ãƒ”ãƒŠãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        with st.spinner(message):
            yield
    
    def show_progress_bar(self, progress: float, message: str = "") -> None:
        """
        é€²æ—ãƒãƒ¼ã‚’è¡¨ç¤º
        
        Args:
            progress: é€²æ—ï¼ˆ0.0-1.0ï¼‰
            message: é€²æ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        st.progress(progress)
        if message:
            st.text(message)
    
    def show_status(self, message: str, status_type: str = "info") -> None:
        """
        ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        
        Args:
            message: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            status_type: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆinfo, success, warning, errorï¼‰
        """
        if status_type == "success":
            st.success(message)
        elif status_type == "warning":
            st.warning(message)
        elif status_type == "error":
            st.error(message)
        else:
            st.info(message)
    
    def show_cancel_button(self, key: Optional[str] = None) -> bool:
        """
        ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
        
        Args:
            key: ãƒœã‚¿ãƒ³ã®ã‚­ãƒ¼
            
        Returns:
            bool: ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸå ´åˆTrue
        """
        return st.button("â¹ï¸ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", key=key)
    
    def update_progress_with_cancellation(self, progress: float, message: str) -> bool:
        """
        ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèªä»˜ãã§é€²æ—ã‚’æ›´æ–°
        
        Args:
            progress: é€²æ—ï¼ˆ0.0-1.0ï¼‰
            message: é€²æ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            
        Returns:
            bool: ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãŒè¦æ±‚ã•ã‚ŒãŸå ´åˆTrue
        """
        self.show_progress_bar(progress, message)
        return self.show_cancel_button()
    
    # QAã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ¡ã‚½ãƒƒãƒ‰
    
    def process_question(self, question: str) -> Optional[Dict[str, Any]]:
        """
        è³ªå•ã‚’å‡¦ç†ï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        
        Args:
            question: è³ªå•å†…å®¹
            
        Returns:
            Optional[Dict[str, Any]]: QAçµæœ
        """
        try:
            if not self.rag_pipeline:
                return None
            
            conversation_history = self.chat_manager.get_conversation_history_for_qa()
            
            with self.show_spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                result = self.rag_pipeline.answer_question(
                    question,
                    conversation_history=conversation_history
                )
            
            return result
            
        except QAError as e:
            self.logger.error(f"QAã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            self.show_status(f"è³ªå•ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", "error")
            return None
        except Exception as e:
            self.logger.error(f"è³ªå•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            self.show_status("äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", "error")
            return None
    
    def process_streaming_question(self, question: str) -> Optional[Iterator[Dict[str, Any]]]:
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å½¢å¼ã§è³ªå•ã‚’å‡¦ç†
        
        Args:
            question: è³ªå•å†…å®¹
            
        Returns:
            Optional[Iterator[Dict[str, Any]]]: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœ
        """
        try:
            if not self.rag_pipeline:
                return None
            
            conversation_history = self.chat_manager.get_conversation_history_for_qa()
            
            return self.rag_pipeline.answer_question_stream(
                question,
                conversation_history=conversation_history
            )
            
        except Exception as e:
            self.logger.error(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è³ªå•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            self.show_status("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", "error")
            return None
    
    def process_streaming_question_with_cancel(self, question: str) -> Optional[Dict[str, Any]]:
        """
        ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ©Ÿèƒ½ä»˜ãã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è³ªå•å‡¦ç†
        
        Args:
            question: è³ªå•å†…å®¹
            
        Returns:
            Optional[Dict[str, Any]]: å‡¦ç†çµæœï¼ˆã‚­ãƒ£ãƒ³ã‚»ãƒ«æ™‚ã¯Noneï¼‰
        """
        try:
            stream = self.process_streaming_question(question)
            if not stream:
                return None
            
            result = None
            for chunk in stream:
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç¢ºèªï¼ˆå®Ÿè£…æ™‚ã«UIãƒ­ã‚¸ãƒƒã‚¯ã¨é€£æºï¼‰
                if self.show_cancel_button():
                    return None
                
                if chunk.get('type') == 'complete':
                    result = chunk
                    break
            
            return result
            
        except Exception as e:
            self.logger.error(f"ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä»˜ãã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def display_qa_result(self, qa_result: Dict[str, Any]) -> None:
        """
        QAçµæœã‚’è¡¨ç¤º
        
        Args:
            qa_result: QAçµæœ
        """
        try:
            with st.chat_message("assistant"):
                # å›ç­”è¡¨ç¤º
                answer = qa_result.get('answer', '')
                st.write(answer)
                
                # ã‚½ãƒ¼ã‚¹æƒ…å ±è¡¨ç¤º
                sources = qa_result.get('sources', [])
                if sources:
                    self.chat_manager._display_sources(sources)
                
                # å‡¦ç†æ™‚é–“è¡¨ç¤º
                processing_time = qa_result.get('processing_time', 0)
                if processing_time > 0:
                    st.caption(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
                    
        except Exception as e:
            self.logger.error(f"QAçµæœè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
            st.error("çµæœã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")