#!/usr/bin/env python3
"""
èµ·å‹•æ™‚ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã®çµ±åˆãƒ†ã‚¹ãƒˆ

ISSUE-016: èµ·å‹•æ™‚ã«Ollamaã®å¿…é ˆãƒ¢ãƒ‡ãƒ«ï¼ˆllama3:8bã€nomic-embed-textï¼‰ãŒ
ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã€ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«
é©åˆ‡ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’è¡¨ç¤ºã™ã‚‹æ©Ÿèƒ½ã®å‹•ä½œç¢ºèª
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.logic.ollama_checker import OllamaModelChecker, ModelCheckResult


def test_startup_model_check():
    """èµ·å‹•æ™‚ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("ISSUE-016: èµ·å‹•æ™‚ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    try:
        # OllamaModelCheckerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        checker = OllamaModelChecker()
        print(f"âœ… OllamaModelCheckeråˆæœŸåŒ–æˆåŠŸ")
        
        # å¿…é ˆãƒ¢ãƒ‡ãƒ«ç¢ºèª
        print(f"\nğŸ“‹ å¿…é ˆãƒ¢ãƒ‡ãƒ«è¨­å®šç¢ºèª:")
        for model_name, model_info in checker.REQUIRED_MODELS.items():
            print(f"   - {model_info.display_name}")
            print(f"     åå‰: {model_info.name}")
            print(f"     ç”¨é€”: {model_info.description}")
            print(f"     ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰: {model_info.install_command}")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        print(f"\nğŸ” Ollamaãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")
        check_result = checker.check_required_models()
        
        print(f"\nğŸ“Š ãƒã‚§ãƒƒã‚¯çµæœ:")
        print(f"   - Ollamaæ¥ç¶š: {'âœ… æˆåŠŸ' if check_result.ollama_connected else 'âŒ å¤±æ•—'}")
        print(f"   - å¿…é ˆãƒ¢ãƒ‡ãƒ«å®Œå‚™: {'âœ… ã¯ã„' if check_result.is_available else 'âŒ ã„ã„ãˆ'}")
        
        if check_result.available_models:
            print(f"   - åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«æ•°: {len(check_result.available_models)}")
            for model in check_result.available_models:
                print(f"     âœ… {model}")
        
        if check_result.missing_models:
            print(f"   - ä¸è¶³ãƒ¢ãƒ‡ãƒ«æ•°: {len(check_result.missing_models)}")
            for model in check_result.missing_models:
                print(f"     âŒ {model.display_name} ({model.name})")
        
        if check_result.error_message:
            print(f"   - ã‚¨ãƒ©ãƒ¼: {check_result.error_message}")
        
        # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        if check_result.missing_models:
            print(f"\nğŸ“– ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰:")
            guide = checker.get_installation_guide(check_result.missing_models)
            print("â”€" * 60)
            print(guide)
            print("â”€" * 60)
        
        # çµæœåˆ¤å®š
        if check_result.is_available:
            print(f"\nğŸ‰ ã™ã¹ã¦ã®å¿…é ˆãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™ï¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã§ãã¾ã™ã€‚")
            return True
        else:
            print(f"\nâš ï¸  ä¸è¶³ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚ä¸Šè¨˜ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦ãã ã•ã„ã€‚")
            return False
            
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return False


def simulate_app_startup():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print(f"\n" + "=" * 60)
    print("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)
    
    try:
        # OllamaModelCheckerã§ãƒã‚§ãƒƒã‚¯
        checker = OllamaModelChecker()
        check_result = checker.check_required_models()
        
        print(f"ğŸš€ LocalKnowledgeAgentèµ·å‹•ä¸­...")
        
        if not check_result.ollama_connected:
            print(f"âŒ Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")
            print(f"   è§£æ±ºæ–¹æ³•:")
            print(f"   1. OllamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
            print(f"   2. 'ollama serve' ã‚³ãƒãƒ³ãƒ‰ã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•")
            return False
        
        if not check_result.is_available:
            print(f"âŒ å¿…é ˆãƒ¢ãƒ‡ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            print(f"   ä¸è¶³ãƒ¢ãƒ‡ãƒ«: {', '.join([m.name for m in check_result.missing_models])}")
            print(f"   ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„")
            return False
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯å®Œäº† - ã™ã¹ã¦ã®å¿…é ˆãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½")
        print(f"âœ… ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•å¯èƒ½")
        return True
        
    except Exception as e:
        print(f"âŒ èµ·å‹•ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return False


if __name__ == "__main__":
    print("LocalKnowledgeAgent èµ·å‹•æ™‚ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ\n")
    
    # åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    basic_test_success = test_startup_model_check()
    
    # èµ·å‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    startup_simulation_success = simulate_app_startup()
    
    # ç·åˆçµæœ
    print(f"\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if basic_test_success else 'âŒ å¤±æ•—'}")
    print(f"èµ·å‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {'âœ… æˆåŠŸ' if startup_simulation_success else 'âŒ å¤±æ•—'}")
    
    if basic_test_success and startup_simulation_success:
        print(f"\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print(f"   èµ·å‹•æ™‚ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")
        sys.exit(0)
    else:
        print(f"\nâš ï¸  ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        print(f"   å¿…è¦ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)